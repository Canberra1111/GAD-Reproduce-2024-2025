{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24caa24a-9627-4bd7-806c-0be1bcaeeb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import ddpm.core.logger as Logger\n",
    "import ddpm.core.metrics as Metrics\n",
    "import ddpm.data as Data\n",
    "from ddpm.feature_test import pre_test\n",
    "import ddpm.model as Model\n",
    "import math\n",
    "import sys\n",
    "\n",
    "def ddpmFeatures(features, non_features):\n",
    "    \"\"\"\n",
    "    修复后的ddpmFeatures函数，避免argparse冲突\n",
    "    \"\"\"\n",
    "    # 保存原始命令行参数\n",
    "    original_argv = sys.argv.copy()\n",
    "    \n",
    "    try:\n",
    "        # 临时设置ddmp需要的参数\n",
    "        sys.argv = [\n",
    "            'feature_train.py',\n",
    "            '-c', 'ddpm/config/train.json',\n",
    "            '-p', 'train'\n",
    "        ]\n",
    "        \n",
    "        # 现在可以安全地使用argparse\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('-c', '--config', type=str, default='ddpm/config/train.json',\n",
    "                            help='JSON file for configuration')\n",
    "        parser.add_argument('-p', '--phase', type=str, choices=['train', 'val'],\n",
    "                            help='Run either train(training) or val(generation)', default='train')\n",
    "        parser.add_argument('-gpu', '--gpu_ids', type=str, default=None)\n",
    "        parser.add_argument('-debug', '-d', action='store_true')\n",
    "        parser.add_argument('-enable_wandb', action='store_true')\n",
    "        parser.add_argument('-log_wandb_ckpt', action='store_true')\n",
    "        parser.add_argument('-log_eval', action='store_true')\n",
    "        \n",
    "        # parse configs\n",
    "        args = parser.parse_args()\n",
    "        opt = Logger.parse(args)\n",
    "        # Convert to NoneDict, which return None for missing key.\n",
    "        opt = Logger.dict_to_nonedict(opt)\n",
    "        \n",
    "        # logging\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        Logger.setup_logger(None, opt['path']['log'],\n",
    "                            'train', level=logging.INFO, screen=True)\n",
    "        Logger.setup_logger('val', opt['path']['log'], 'val', level=logging.INFO)\n",
    "        logger = logging.getLogger('base')\n",
    "        logger.info(Logger.dict2str(opt))\n",
    "        tb_logger = SummaryWriter(log_dir=opt['path']['tb_logger'])\n",
    "        \n",
    "        for phase, dataset_opt in opt['datasets'].items():\n",
    "            if phase == 'train' and args.phase != 'val':\n",
    "                train_set = Data.create_dataset(dataset_opt, features, phase)\n",
    "                train_loader = Data.create_dataloader(train_set, dataset_opt, phase)\n",
    "        logger.info('Initial Dataset Finished')\n",
    "        \n",
    "        # model \n",
    "        diffusion = Model.create_model(opt)\n",
    "        logger.info('Initial Model Finished')\n",
    "        \n",
    "        # Train resume_state=None 所以current_step=0，current_epoch=0\n",
    "        current_step = diffusion.begin_step\n",
    "        current_epoch = diffusion.begin_epoch\n",
    "        n_epoch = opt['train']['n_epoch']\n",
    "        if opt['path']['resume_state']:\n",
    "            logger.info('Resuming training from epoch: {}, iter: {}.'.format(\n",
    "                current_epoch, current_step))\n",
    "        diffusion.set_new_noise_schedule(\n",
    "            opt['model']['beta_schedule'][opt['phase']], schedule_phase=opt['phase'])\n",
    "        \n",
    "        # save_model_iter\n",
    "        save_model_iter = math.ceil(train_set.__len__() / opt['datasets']['train']['batch_size'])\n",
    "        while current_epoch < n_epoch:\n",
    "            current_epoch += 1\n",
    "            for _, train_data in enumerate(train_loader):\n",
    "                current_step += 1\n",
    "                if current_epoch > n_epoch:\n",
    "                    break\n",
    "                diffusion.feed_data(train_data)\n",
    "                diffusion.optimize_parameters()\n",
    "                # log\n",
    "                if current_epoch % opt['train']['print_freq'] == 0 and current_step % save_model_iter == 0:\n",
    "                    logs = diffusion.get_current_log()\n",
    "                    message = '<epoch:{:3d}, iter:{:8,d}> '.format(\n",
    "                        current_epoch, current_step)\n",
    "                    for k, v in logs.items():\n",
    "                        message += '{:s}: {:.4e} '.format(k, v)\n",
    "                        tb_logger.add_scalar(k, v, current_step)\n",
    "                    logger.info(message)\n",
    "                if current_epoch % opt['train']['save_checkpoint_freq'] == 0 and current_step % save_model_iter == 0:\n",
    "                    logger.info('Saving models and training states.')\n",
    "                    diffusion.save_network(current_epoch, current_step)\n",
    "        logger.info('End of training.')\n",
    "        \n",
    "        return pre_test(features)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ddmpFeatures failed: {e}\")\n",
    "        print(\"Returning original features as fallback\")\n",
    "        return features\n",
    "        \n",
    "    finally:\n",
    "        # 恢复原始命令行参数\n",
    "        sys.argv = original_argv\n",
    "\n",
    "\n",
    "def ddpmFeatures_safe(features, non_features):\n",
    "    \"\"\"\n",
    "    安全版本的ddmpFeatures，完全避免argparse\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from types import SimpleNamespace\n",
    "        \n",
    "        # 创建模拟的args对象，不使用argparse\n",
    "        args = SimpleNamespace()\n",
    "        args.config = 'ddpm/config/train.json'\n",
    "        args.phase = 'train'\n",
    "        args.gpu_ids = None\n",
    "        args.debug = False\n",
    "        args.enable_wandb = False\n",
    "        args.log_wandb_ckpt = False\n",
    "        args.log_eval = False\n",
    "        \n",
    "        opt = Logger.parse(args)\n",
    "        opt = Logger.dict_to_nonedict(opt)\n",
    "        \n",
    "        # logging\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        Logger.setup_logger(None, opt['path']['log'],\n",
    "                            'train', level=logging.INFO, screen=True)\n",
    "        Logger.setup_logger('val', opt['path']['log'], 'val', level=logging.INFO)\n",
    "        logger = logging.getLogger('base')\n",
    "        logger.info(Logger.dict2str(opt))\n",
    "        tb_logger = SummaryWriter(log_dir=opt['path']['tb_logger'])\n",
    "        \n",
    "        for phase, dataset_opt in opt['datasets'].items():\n",
    "            if phase == 'train' and args.phase != 'val':\n",
    "                train_set = Data.create_dataset(dataset_opt, features, phase)\n",
    "                train_loader = Data.create_dataloader(train_set, dataset_opt, phase)\n",
    "        logger.info('Initial Dataset Finished')\n",
    "        \n",
    "        # model \n",
    "        diffusion = Model.create_model(opt)\n",
    "        logger.info('Initial Model Finished')\n",
    "        \n",
    "        # 训练逻辑\n",
    "        current_step = diffusion.begin_step\n",
    "        current_epoch = diffusion.begin_epoch\n",
    "        n_epoch = opt['train']['n_epoch']\n",
    "        if opt['path']['resume_state']:\n",
    "            logger.info('Resuming training from epoch: {}, iter: {}.'.format(\n",
    "                current_epoch, current_step))\n",
    "        diffusion.set_new_noise_schedule(\n",
    "            opt['model']['beta_schedule'][opt['phase']], schedule_phase=opt['phase'])\n",
    "        \n",
    "        save_model_iter = math.ceil(train_set.__len__() / opt['datasets']['train']['batch_size'])\n",
    "        while current_epoch < n_epoch:\n",
    "            current_epoch += 1\n",
    "            for _, train_data in enumerate(train_loader):\n",
    "                current_step += 1\n",
    "                if current_epoch > n_epoch:\n",
    "                    break\n",
    "                diffusion.feed_data(train_data)\n",
    "                diffusion.optimize_parameters()\n",
    "                \n",
    "                if current_epoch % opt['train']['print_freq'] == 0 and current_step % save_model_iter == 0:\n",
    "                    logs = diffusion.get_current_log()\n",
    "                    message = '<epoch:{:3d}, iter:{:8,d}> '.format(current_epoch, current_step)\n",
    "                    for k, v in logs.items():\n",
    "                        message += '{:s}: {:.4e} '.format(k, v)\n",
    "                        tb_logger.add_scalar(k, v, current_step)\n",
    "                    logger.info(message)\n",
    "                    \n",
    "                if current_epoch % opt['train']['save_checkpoint_freq'] == 0 and current_step % save_model_iter == 0:\n",
    "                    logger.info('Saving models and training states.')\n",
    "                    diffusion.save_network(current_epoch, current_step)\n",
    "        \n",
    "        logger.info('End of training.')\n",
    "        return pre_test(features)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"DDPM training failed: {e}\")\n",
    "        print(\"Returning original features as fallback\")\n",
    "        return features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
